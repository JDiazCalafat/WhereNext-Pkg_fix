% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PreFindNext.R
\name{PreFindNext}
\alias{PreFindNext}
\title{Initial computation of complementarity and matrices for iterative site selection}
\usage{
PreFindNext(gdm.rast, occ.table, env.vars, subset.size = 1000,
  search.type = "1", candidate.sites)
}
\arguments{
\item{gdm.rast}{A gdm model object}

\item{occ.table}{A data frame with species occurrence information. Must contain a decimalLongitude and decimalLatitude field (x and y coordinates, respectively)ate field}

\item{env.vars}{A rasterStack object of gdm transformed environmental predictors. Obtained by using the gdm.transform option in the gdm package.}

\item{subset.size}{An integer specifying the number of demand points for continuous p-median evaluation. Default = 10000. See Faith & Walker (1996) and Manion (2009).}

\item{search.type}{Either a "1" or "2" string specifying whether to identify potential survey sites across the entire study area or from a set of candidate sites, respectively.}

\item{candidate.sites}{A data frame of candidate survey sites. Only necessary when using search.type="2". Must only have columns decimalLongitude and decimalLatitude, in that order.}
}
\value{
A list with the following objects:
\describe{
  \item{out.raster}{A raster object displaying the complementarity of candidate sites}
  \item{initED}{A relative measure of total current survey coverage}
  \item{outED}{A relative measure of total survey coverage if the suggested site is surveyed}
  \item{selCoords}{Coordinates of the suggested survey site (i.e. the most complementary)}
  \item{params}{A list object to input in function FindNext}
}
}
\description{
Initial computation of complementarity and matrices for iterative site selection
}
\details{
This function implements the stage 1 algorithm proposed by Manion & Ridges (2009). Specifically, it computes the minimum
environmental distance from a set of demand points to survey sites (nnDistance in params object) and the
environmental distance from demand points to candidate sites, either all non-sampled cells in the input grids or
a user-defined set of candidate sites (m2 in params object). Then it finds the cell
(XY coordinates provided in selCoords) that reduces the most the environmental distance
 to demand points compared to the survey sites (nnDistanceUpdated in params object).
 The raster output measures each cells' relative contribution to improve survey
 coverage or complementarity if the cell is selected (Funk et al. 2005).
}
\note{
This is a very memory intensive function as it will try to fit a matrix of
roughly subset.size rows by ncell(env.vars) columns. PreFindNext will request that
you have at least 3 times the necessary memory available in your system to run.
}
\examples{
#' \dontrun{
#To compute cell stats for colombian bats
library(ISOcodes)
library(lubridate)
library(raster)
library(rgbif)
library(WhereNext)
#Get occurrence data
gbif.key <- name_backbone(name = "Chiroptera")
gbif.res <- DownloadGBIF(gbif.key$orderKey, "your username", "your email", "your password", "CO") #Enter your GBIF credentials here

#Get environmental data
col <- getData("GADM", country="COL",level=0)
env.vars <- getData("worldclim", var="bio", res=5)
env.vars <- crop(env.vars, col)
env.vars <- mask(env.vars, col)
env.vars <- Normalize(env.vars) #Normalize environmental variables
env.vars <- RemCorrLayers(env.vars, 0.8) #Remove variables correlated more than r=0.8.

#Do minimal occ.table cleaning
occ.table <-gbif.res$occ.table
occ.table$eventDate <- as_date(occ.table$eventDate)
occ.table$individualCount <- 1 #Data is presence only
occ.table$countryCode <- ISO_3166_1$Alpha_3[match(occ.table$countryCode, ISOcodes::ISO_3166_1$Alpha_2)] #Change ISO2 for ISO3 as required by CoordinateCleaner
occ.table.clean <- subset(occ.table, !is.na(eventDate) & taxonRank=="SPECIES")
rownames(occ.table.clean) <- 1:nrow(occ.table.clean)
occ.table.clean <- CoordinateCleaner::clean_coordinates(occ.table.clean,
                                                        lon="decimalLongitude",
                                                        lat="decimalLatitude",
                                                        species="species",
                                                        countries = "countryCode",
                                                        value="clean",
                                                        tests=c("countries","capitals","centroids", "equal", "gbif",
                                                                "institutions", "outliers", "seas","zeros"))

#Estimate cell sampling stats & filter occurrence data
occ.table.clean$cell <- cellFromXY(env.vars, occ.table.clean[, c("decimalLongitude","decimalLatitude")])
cell.stats <- RichSamp(occ.table.clean, env.vars, c("decimalLongitude","decimalLatitude","eventDate","species","individualCount","cell"))
selected.cells <- cell.stats$cell[which(cell.stats$n>3&cell.stats$Species>5)] #Consider places with at least 3 sampling events and 5 species recorded as well sampled
occ.table.sel <- occ.table.clean[which(occ.table.clean$cell \%in\% selected.cells), ] #Use only ocurrences of well sampled cells
#Run and map GDM
m1 <- RunGDM(occ.table.sel, env.vars, "bray", TRUE, TRUE, c("species", "decimalLongitude", "decimalLatitude"))
plotRGB(m1$gdm.map$pcaRast)

#Find initial survey suggestions
init <- PreFindNext(m1$gdm.res, m1$occ.table, m1$gdm.rasters, subset.size=1000, search.type="1")
plot(init$out.raster)
points(init$selCoords)

}
}
\references{
Funk, V. A., Richardson, K. S., & Ferrier, S. (2005). Survey-gap analysis in expeditionary research: where
do we go from here?. Biological Journal of the Linnean Society, 85(4), 549-567.

Manion, G., & Ridges, M. (2009). An optimisation of the survey gap analysis technique to
minimise computational complexity and memory resources in order to accommodate fine grain environmental and
site data. In 18th World IMACS/MODSIM Congress, Cairns, Australia (pp. 13-17).
}
